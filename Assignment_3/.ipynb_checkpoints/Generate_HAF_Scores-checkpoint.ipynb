{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import time \n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import string \n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def str_variable(variable, name, tabs=0):\n",
    "    return  '{}{}: {}'.format('\\t' * tabs, name, variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def alphabet_generator():\n",
    "    for letter in string.ascii_lowercase:\n",
    "        yield letter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use msms to generate a populations growing under selection constraint. Generate many\n",
    "samples (100) for each of 5 different time points since onset of selection, but plan your\n",
    "simulations as it is a forward simulation, and may take some time. Use the following\n",
    "parameters: N = 104, s = 0.1, θ = ρ = 250, n = 200. Use the -SI option to sample at different times since onset of selection. Your selection of sampling times should include time before fixation of the favored allele, and times after fixation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the average of HAF scores\n",
    "separately for carriers of the favored allele, and the non-carriers as a function of time since\n",
    "onset of selection. The x-axis of your plot should be the time since onset of selection, while\n",
    "the y-axis is the HAF-score in units of θn. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run MSMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_dataset(out_fn='sample.txt', population_size = 10000, \\\n",
    "                     s = 0.1, time = 1, favored_site = 0.50000, freq = 0.00001):\n",
    "    generation = float(time) / (4 * population_size)\n",
    "    sAa = 2*population_size*s\n",
    "    sAA = 2 * sAa\n",
    "    #     freq = float(1)/(2*population_size)\n",
    "    #     freq = '{:.5f}'.format(freq)\n",
    "    \n",
    "    cmd = 'java -jar ' \n",
    "    cmd += '/frazer01/home/joreyna/shared_drive/CSE-280a/Assignment_2/msms/lib/msms.jar '\n",
    "    cmd += '-ms 200 100 -r 250 -t 250 -N {} -SAa {} -SAA {} '.format(population_size, sAa, sAA)\n",
    "    cmd += '-SF {} {} -Sp 0.50000 -Smark -threads 4 -l 1 1 1000000000 '.format(generation, freq) \n",
    "    cmd += '1> /frazer01/home/joreyna/repos/CSE-280a/Assignment_3/{}'.format(out_fn) \n",
    "    \n",
    "    print('cmd: {}'.format(cmd))\n",
    "    return subprocess.check_call(cmd, shell=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MSMS results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def load_dataset(fn):\n",
    "    with open(fn, 'rb') as f:\n",
    "        cmd = f.readline()\n",
    "        code = f.readline()\n",
    "        blank = f.readline()\n",
    "        drow = blank\n",
    "        dataset = []\n",
    "        count = 0\n",
    "        while drow != '':\n",
    "\n",
    "            if drow == '\\n':\n",
    "                slashes = f.readline()\n",
    "                segsites = f.readline()\n",
    "                positions = f.readline()\n",
    "                drow = positions \n",
    "\n",
    "            else:\n",
    "                positions = drow.strip().replace('positions: ', '')\n",
    "                positions = [float(x) for x in positions.split()]\n",
    "                data = [positions]\n",
    "                drow = f.readline()\n",
    "                while drow != '\\n':\n",
    "                    drow = [int(x) for x in drow.strip()]\n",
    "                    data.append(drow)\n",
    "                    drow = f.readline()\n",
    "                dataset.append(data)\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract the carriers and non-carriers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rename_and_remove_duplicates_column_names(col_names):\n",
    "    col_dict = defaultdict(alphabet_generator)\n",
    "    new_col_names = []\n",
    "    for col in col_names:\n",
    "        new_col_names.append('{}_{}'.format(col, col_dict[col].next()))\n",
    "    return new_col_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate HAF dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def calculate_haf_data(snp_df):\n",
    "    \"\"\"\n",
    "    Generate a list of lists with HAF values.\n",
    "    \"\"\"\n",
    "    global index, col, entry, row_data\n",
    "\n",
    "    \n",
    "    frequencies = snp_df.sum()\n",
    "    haf_data = [] \n",
    "    for index in snp_df.index.tolist():\n",
    "        row_data = []\n",
    "        for col in snp_df.columns.tolist():\n",
    "            entry = snp_df.ix[index, col]\n",
    "            \n",
    "            try:\n",
    "                if len(entry) > 1:\n",
    "                    entry = entry.iloc[0]\n",
    "            except:\n",
    "                entry = entry\n",
    "            \n",
    "            if entry == 1:\n",
    "                row_data.append(frequencies[col])\n",
    "            else:\n",
    "                row_data.append(0)\n",
    "        haf_data.append(row_data)\n",
    "    return haf_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the analysis to multiple time points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Running MSMS\n",
    "human_time = sys.argv[0]\n",
    "time = sys.argv[1]\n",
    "freq = sys.argv[2]\n",
    "selective_allele = 0.50000\n",
    "msms_fn = 'timepoint_{}.txt'.format(time)\n",
    "generate_dataset(out_fn = msms_fn, population_size = 10000, \\\n",
    "                 s = 0.1, time = time, favored_site = selective_allele, \n",
    "                 freq = freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Loading the dataset \n",
    "dataset = load_dataset(msms_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Calculating the HAF scores \n",
    "dataset_df  = []\n",
    "total_carriers, total_non_carriers = (0,0)\n",
    "for data in dataset:\n",
    "    data_df = pd.DataFrame(data[1:], columns=data[0]) \n",
    "    data_df.columns = rename_and_remove_duplicates_column_names(data_df.columns.tolist())\n",
    "    #     print('Are there any duplicate columns?')\n",
    "    #     print(data_df.columns[data_df.columns.duplicated(keep=False)])\n",
    "    \n",
    "    selective_allele_idx = data[0].index(selective_allele)\n",
    "    #     print('Are we correctly pointing at the selective allele?')\n",
    "    #     print(data_df.columns.tolist()[selective_allele_idx])\n",
    "    \n",
    "    data_df.rename(columns={'0.5_a': 'favored'}, inplace=True)\n",
    "    #     print('Are we correctly changing the name of the column?')\n",
    "    #     print(data_df.columns.tolist()[selective_allele_idx])\n",
    "    dataset_df.append(data_df)\n",
    "dataset_df = pd.concat(dataset_df)\n",
    "dataset_df.fillna(value=0, inplace=True)\n",
    "\n",
    "carriers_df = dataset_df[dataset_df.ix[:, 'favored'] == 1]\n",
    "non_carriers_df = dataset_df[dataset_df.ix[:, 'favored'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "carriers_df = dataset_df[dataset_df.ix[:, 'favored'] == 1]\n",
    "carrier_haf_df = pd.DataFrame(calculate_haf_data(carriers_df))\n",
    "carriers_haf_scores = carrier_haf.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "carriers_haf_scores.to_csv('results/carrier_haf_scores_{}.tsv'.format(human_tp), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "non_carriers_df = dataset_df[dataset_df.ix[:, 'favored'] == 0]\n",
    "non_carrier_haf_df = pd.DataFrame(calculate_haf_data(non_carriers_df))\n",
    "non_carriers_haf_scores = non_carrier_haf_df.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "non_carriers_haf_scores.to_csv('results/non_carriers_haf_scores_{}.tsv'.format(human_tp), sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
